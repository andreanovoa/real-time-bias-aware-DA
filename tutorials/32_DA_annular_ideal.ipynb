{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TUTORIAL: \n",
    "# Data assimilation using real experimental data\n",
    "\n",
    "We can now put everything we have learned together. \n",
    "\n",
    "We can investigate two scenarios:\n",
    "\n",
    "A) Assume that we have access to the post-processed data and assimilate it. This situation simplifies the problem as the experimental data is not biased (see tutorial TA_azimuthal_data to see how the raw data is biased).\n",
    "-   Truth: post-processed data \n",
    "-   Observations: post-processed data + noise (possibly coloured noise)\n",
    "\n",
    "B) Assume a realistic setting in which the post-processed data is not available on the fly to input to the data assimilation algorithm. Here, we need to address the issue of biased observations.\n",
    "-   Truth: post-processed data\n",
    "-   Observations: raw data\n",
    "\n",
    "In this tutorial we will work with option A. For option B go to the tutorial ```11_DA_annular_raw.ipynb```."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "764b9fea212048bd"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from essentials.physical_models import Annular\n",
    "from essentials.bias_models import ESN\n",
    "import scipy.io as sio\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "\n",
    "if os.path.isdir('/mscott/'):\n",
    "    data_folder = '/mscott/an553/data/'  # set working directory to \n",
    "else:\n",
    "    data_folder = \"../data/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:14.932484Z",
     "start_time": "2024-03-07T16:18:14.719001Z"
    }
   },
   "id": "3ed20651c653ef43",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load data \n",
    "Create the reference truth and the observations.\n",
    "\n",
    "The code below can be compacted with the function ```create_truth```\n",
    "```\n",
    "  \n",
    "from essentials.create import create_truth\n",
    "truth = create_truth(filename, t_start, t_stop, Nt_obs, std_obs, noise_type='gauss', post_processed=True)\n",
    "```\n",
    "\n",
    "The output ```truth``` is a dictionary containing\n",
    "```\n",
    "dict(y_raw=y_raw, y_true=y_true, t=t_true, dt=dt_t, t_obs=t_obs, y_obs=y_obs, \n",
    "     dt_obs=Nt_obs * dt_t, std_obs=std_obs)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13e856dabc8c870"
  },
  {
   "cell_type": "code",
   "source": [
    "ER = 0.5625\n",
    "filename = data_folder + 'annular/ER_{}'.format(ER)\n",
    "\n",
    "\n",
    "# Select the observations time-window\n",
    "t_start = 1.0\n",
    "t_stop = t_start + Annular.t_CR * 6\n",
    "t_max = 7\n",
    "Nt_obs = 35\n",
    "\n",
    "# Load experimental data\n",
    "mat = sio.loadmat(filename + '.mat')\n",
    "y_true, t_true = [mat[key].squeeze() for key in ['y_filtered', 't']]\n",
    "\n",
    "i1 = np.argmin(abs(t_true - t_max)) \n",
    "y_true, t_true = [xx[:i1] for xx in [y_true, t_true]]\n",
    "\n",
    "Nt, Nq = y_true.shape\n",
    "dt_t = t_true[1] - t_true[0]\n",
    "\n",
    "# Add noise to the truth to \"create\" the observations\n",
    "std_obs = 0.1\n",
    "noise = rng.multivariate_normal(np.zeros(Nq), np.eye(Nq) * std_obs ** 2, Nt)\n",
    "y_raw = y_true + noise * y_true\n",
    "\n",
    "\n",
    "# Sample the observations\n",
    "obs_idx = np.arange(t_start // dt_t, t_stop // dt_t + 1, Nt_obs, dtype=int)\n",
    "y_obs, t_obs = [xx[obs_idx] for xx in [y_raw, t_true]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:19.938565Z",
     "start_time": "2024-03-07T16:18:14.953041Z"
    }
   },
   "id": "d4b6d568e2a77fba",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.plotResults import plot_truth\n",
    "plot_truth(y_true=y_true, y_raw=y_raw, t=t_true, t_obs=t_obs, y_obs=y_obs, dt=dt_t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:23.984240Z",
     "start_time": "2024-03-07T16:18:19.951024Z"
    }
   },
   "id": "48a3918ed2e2da4f",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define the forecast model\n",
    "This is the physical model which we will use to model the true data.\n",
    "Here, we select the filter parameters and create ensemble\n",
    "\n",
    "*The code below can be compacted as*\n",
    "```\n",
    "from essentials.create import create_ensemble\n",
    "ensemble = create_ensemble(model=Annular, **filter_params)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5497d4de7a6285"
  },
  {
   "cell_type": "code",
   "source": [
    "print(Annular.c2beta_from_ER(ER),\n",
    "      Annular.nu_from_ER(ER))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:23.984674Z",
     "start_time": "2024-03-07T16:18:23.984019Z"
    }
   },
   "id": "accc0e5dd4f2dfad",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "alpha0 = dict(nu=(5., 30.),\n",
    "              c2beta=(10, 40),\n",
    "              kappa=(1.E-4, 1.3E-4),\n",
    "              # epsilon=(0.0001, 0.03),\n",
    "              omega=(1090 * 2 * np.pi, 1100 * 2 * np.pi),\n",
    "              # theta_b=(0.5, 0.7),\n",
    "              # theta_e=(0.5, 0.8)\n",
    "              )\n",
    "\n",
    "alpha0_mean = dict()\n",
    "for alpha, lims in alpha0.items():\n",
    "    alpha0_mean[alpha] = 0.5 * (lims[0] + lims[1])\n",
    "\n",
    "ensemble = Annular(**alpha0_mean)\n",
    "\n",
    "filter_params = {'m': 10, \n",
    "                 'inflation': 1.0,\n",
    "                 'std_psi': 0.3,\n",
    "                 'std_a': alpha0}\n",
    "\n",
    "# Forecast model to initialise the ensemble after transient\n",
    "state, t_ = ensemble.time_integrate(int(ensemble.t_CR / ensemble.dt))\n",
    "ensemble.update_history(state[-1], reset=True)\n",
    "\n",
    "ensemble.init_ensemble(**filter_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:24.069262Z",
     "start_time": "2024-03-07T16:18:23.993587Z"
    }
   },
   "id": "cb85d5a0d4292724",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Visualize ensemble initialization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50536fb1a6b9c057"
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.plotResults import plot_ensemble\n",
    "plot_ensemble(ensemble, reference_params={'kappa': 1e-4, 'omega': 2 * np.pi})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:25.072542Z",
     "start_time": "2024-03-07T16:18:24.019273Z"
    }
   },
   "id": "f28a3485e425797f",
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Train an ESN to model the model bias\n",
    "The procedure is the following\n",
    "\n",
    "&emsp; i. Initialise ESN Bias class object\n",
    "&emsp; ii. Create synthetic bias to use as training data \n",
    "&emsp; iii. Train the ESN\n",
    "&emsp; iv. Create washout data\n",
    "\n",
    "<br><br>\n",
    "**4.1. Initialise the ESN**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee6d809a7220890b"
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.create import create_bias_training_dataset\n",
    "\n",
    "ensemble_no_bias = ensemble.copy()\n",
    "ensemble_ESN = ensemble.copy()\n",
    "\n",
    "train_params = dict(bias_model=ESN, \n",
    "                    upsample=5,\n",
    "                    N_units=50,\n",
    "                    N_wash=5,\n",
    "                    t_train=ensemble.t_CR * 10,\n",
    "                    t_test=ensemble.t_CR * 2,\n",
    "                    t_val=ensemble.t_CR * 2,\n",
    "                    # Training data generation options\n",
    "                    augment_data=True,\n",
    "                    bayesian_update=False,\n",
    "                    biased_observations=False,\n",
    "                    seed_W=0,\n",
    "                    L=10,\n",
    "                    # Hyperparameter search ranges\n",
    "                    rho_range=(0.5, 1.),\n",
    "                    sigma_in_range=(np.log10(1e-5), np.log10(1e1)),\n",
    "                    tikh_range=[1e-16, 1e-12, 1e-9]\n",
    "                    )\n",
    "ensemble_ESN.init_bias(**train_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:25.078358Z",
     "start_time": "2024-03-07T16:18:25.072676Z"
    }
   },
   "id": "444bd81b95535c72",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**4.2. Create training data**\n",
    "\n",
    "The details of the code inside ```create_bias_training_dataset()``` function is explained in the tutorial ```Class_Bias.ipynb```."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f5829d3c47b6eae"
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = create_bias_training_dataset(y_raw, y_true, ensemble_ESN, **train_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:31.693905Z",
     "start_time": "2024-03-07T16:18:25.080381Z"
    }
   },
   "id": "230e6eee0d515c72",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualize training data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad985113a14459f"
  },
  {
   "cell_type": "code",
   "source": [
    "#TODO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:18:31.701001Z",
     "start_time": "2024-03-07T16:18:31.697956Z"
    }
   },
   "id": "1d09a37e5f71c68e",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**4.3. Train the ESN**\n",
    "\n",
    "The training convergence, hyperparameter optimization and testing results are saved in a pdf file in *figs_ESN* folder."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6683a5661c8f19f1"
  },
  {
   "cell_type": "code",
   "source": [
    "ensemble_ESN.bias.train_bias_model(**train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:19:46.710058Z",
     "start_time": "2024-03-07T16:18:31.703681Z"
    }
   },
   "id": "56a4df7d2b76978e",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4.4. Create washout data**\n",
    "\n",
    "We retrieve from the raw data a ```N_wash``` number of observations to use for initialising the ESN, i.e., to perform the washout. \n",
    "The ESN initialization must be before the fist observation.\n",
    "\n",
    "```\n",
    "from essentials.create import create_washout\n",
    "wash_t, wash_obs = create_washout(ensemble.bias, t=t_true, y_raw=y_raw)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccd93fc9e448fcbd"
  },
  {
   "cell_type": "code",
   "source": [
    "ensemble_ESN.bias.t_init = t_obs[0] - 2 * Nt_obs * dt_t\n",
    "\n",
    "i1 = np.argmin(abs(ensemble_ESN.bias.t_init - t_true))\n",
    "i0 = i1 - ensemble_ESN.bias.N_wash  * ensemble_ESN.bias.upsample \n",
    "\n",
    "wash_obs = y_raw[i0:i1 + 1:ensemble_ESN.bias.upsample]\n",
    "wash_t = t_true[i0:i1 + 1:ensemble_ESN.bias.upsample]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:19:46.713711Z",
     "start_time": "2024-03-07T16:19:46.710853Z"
    }
   },
   "id": "d85d09086c26972",
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Apply data assimilation\n",
    "We now have all the ingredients to start our data assimilation algorithm."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c7739efb6a2c47"
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.DA import dataAssimilation\n",
    "\n",
    "DA_kwargs = dict(y_obs=y_obs, t_obs=t_obs, std_obs=std_obs, wash_obs=wash_obs, wash_t=wash_t)\n",
    "\n",
    "ensemble_ESN.filter = 'rBA_EnKF'\n",
    "ensemble_ESN.regularization_factor = 10.\n",
    "ensemble_no_bias.filter ='EnKF'\n",
    "\n",
    "\n",
    "out = []\n",
    "for ens in [ensemble_no_bias, ensemble_ESN]:\n",
    "# for ens in [ensemble_ESN]:\n",
    "    ens = ens.copy()\n",
    "    ens.t_init = t_obs[0]\n",
    "    ens.inflation = 1.01\n",
    "    \n",
    "    filter_ens = dataAssimilation(ens, **DA_kwargs.copy())\n",
    "    \n",
    "    #Forecast the ensemble further without assimilation\n",
    "    Nt_extra = int(filter_ens.t_CR / filter_ens.dt) * 5\n",
    "    \n",
    "    psi, t = filter_ens.time_integrate(Nt_extra)\n",
    "    filter_ens.update_history(psi, t)\n",
    "    \n",
    "    y = filter_ens.get_observable_hist(Nt_extra)\n",
    "    b, t_b = filter_ens.bias.time_integrate(t=t, y=y)\n",
    "    filter_ens.bias.update_history(b, t_b)\n",
    "    \n",
    "    out.append(filter_ens)\n",
    "    # out[-1] = filter_ens\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:19:58.749004Z",
     "start_time": "2024-03-07T16:19:46.715910Z"
    }
   },
   "id": "dcb58b1103cf7408",
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "truth = dict(y_raw=y_raw, y_true=y_true, t=t_true, dt=dt_t,\n",
    "             t_obs=t_obs, y_obs=y_obs, dt_obs=Nt_obs * dt_t,\n",
    "             std_obs=std_obs, wash_t=wash_t, wash_obs=wash_obs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:19:58.756824Z",
     "start_time": "2024-03-07T16:19:58.755153Z"
    }
   },
   "id": "9dcb9e9795be7639",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.plotResults import plot_states_PDF, plot_RMS_pdf\n",
    "window = (truth[\"t_obs\"][-1], truth[\"t_obs\"][-1] + filter_ens.t_CR * 2)\n",
    "plot_states_PDF(out, truth, nbins=20, window=window)\n",
    "plot_RMS_pdf(out, truth, nbins=20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:20:03.987997Z",
     "start_time": "2024-03-07T16:19:58.852336Z"
    }
   },
   "id": "c10c8756598381d4",
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.plotResults import plot_timeseries, plot_parameters, print_parameter_results\n",
    "\n",
    "\n",
    "reference_params = dict()\n",
    "\n",
    "for key in Annular.params:\n",
    "    reference_params[key] = Annular.defaults[key]\n",
    "\n",
    "reference_params['nu'] = Annular.nu_from_ER(ER)\n",
    "reference_params['c2beta'] = Annular.c2beta_from_ER(ER)\n",
    "\n",
    "print(reference_params.keys())\n",
    "\n",
    "\n",
    "print_parameter_results(out, reference_params)\n",
    "for filter_ens in out:\n",
    "    plot_timeseries(filter_ens, truth)\n",
    "    plot_parameters(filter_ens, truth)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:20:09.198892Z",
     "start_time": "2024-03-07T16:20:03.988496Z"
    }
   },
   "id": "2d438d63ce1902f",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:20:09.200623Z",
     "start_time": "2024-03-07T16:20:09.199348Z"
    }
   },
   "id": "e62e2acc2cd24471",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Plot ensemble spread?\n",
    "# TODO: Plot timeseries PSD"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:20:09.203861Z",
     "start_time": "2024-03-07T16:20:09.202501Z"
    }
   },
   "id": "1910e1d016003fed",
   "execution_count": 43,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
