{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TUTORIAL: \n",
    "# Data assimilation using real experimental data\n",
    "\n",
    "We can now put everything we have learned together. \n",
    "\n",
    "We can investigate two scenarios:\n",
    "\n",
    "A) Assume that we have access to the post-processed data and assimilate it. This situation simplifies the problem as the experimental data is not biased (see tutorial TA_azimuthal_data to see how the raw data is biased).\n",
    "-   Truth: post-processed data \n",
    "-   Observations: post-processed data + noise (possibly coloured noise)\n",
    "\n",
    "B) Assume a realistic setting in which the post-processed data is not available on the fly to input to the data assimilation algorithm. Here, we need to address the issue of biased observations.\n",
    "-   Truth: post-processed data\n",
    "-   Observations: raw data\n",
    "\n",
    "In this tutorial we will work with option A. For option B go to the tutorial ```11_DA_annular_raw.ipynb```."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "764b9fea212048bd"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from essentials.physical_models import Annular\n",
    "from essentials.bias_models import ESN\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "\n",
    "if os.path.isdir('/mscott/'):\n",
    "    data_folder = '/mscott/an553/data/'  # set working directory to \n",
    "else:\n",
    "    data_folder = \"../data/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:08.315359Z",
     "start_time": "2024-04-17T18:47:08.310704Z"
    }
   },
   "id": "3ed20651c653ef43",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load data \n",
    "Create the reference truth and the observations.\n",
    "\n",
    "The function ```create_truth``` is a compact form of the code below\n",
    "```\n",
    "  \n",
    "# Load experimental data\n",
    "mat = sio.loadmat(filename + '.mat')\n",
    "y_true, y_raw, t_true = [mat[key].squeeze() for key in ['y_filtered', 'y_raw', 't']]\n",
    "\n",
    "t_max = 7.\n",
    "i1 = np.argmin(abs(t_true - t_max))\n",
    "y_true, y_raw, t_true = [xx[:i1] for xx in [y_true, y_raw, t_true]]\n",
    "t_true -= t_true[0]\n",
    "\n",
    "Nt, Nq = y_true.shape\n",
    "dt_t = t_true[1] - t_true[0]\n",
    "\n",
    "# Sample the observations\n",
    "obs_idx = np.arange(t_start // dt_t, t_stop // dt_t + 1, Nt_obs, dtype=int)\n",
    "y_obs, t_obs = [xx[obs_idx] for xx in [y_raw, t_true]]\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13e856dabc8c870"
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.create import create_truth\n",
    "ER = 0.4875 + 0.025 * 2 # 0.4875 + np.arange(0, 4) * 0.025\n",
    "\n",
    "t_start = Annular.t_transient\n",
    "t_stop = t_start + Annular.t_CR * 15\n",
    "\n",
    "truth = create_truth(model = data_folder + 'annular/ER_{}'.format(ER),\n",
    "                     t_start = t_start,\n",
    "                     t_stop = t_stop,\n",
    "                     Nt_obs = 35,\n",
    "                     t_max = t_stop + Annular.t_transient,\n",
    "                     post_processed=False\n",
    "                     )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:11.208331Z",
     "start_time": "2024-04-17T18:47:08.316616Z"
    }
   },
   "id": "47e88dbbc92443e5",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The output ```truth``` is a dictionary containing\n",
    "```\n",
    "dict(y_raw=y_raw, y_true=y_true, t=t_true, dt=dt_t, \n",
    "     t_obs=t_obs, y_obs=y_obs, dt_obs=Nt_obs * dt_t, std_obs=std_obs)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c2eb9e465ea1ffe"
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.plotResults import plot_truth\n",
    "plot_truth(**truth)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:14.355071Z",
     "start_time": "2024-04-17T18:47:11.209860Z"
    }
   },
   "id": "3343b64f3a25e224",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define the forecast model\n",
    "This is the physical model which we will use to model the true data.\n",
    "Here, we select the filter parameters and create ensemble\n",
    "\n",
    "*The function ```create_ensemble``` consists of* \n",
    "\n",
    "```\n",
    "alpha0_mean = dict()\n",
    "for alpha, lims in alpha0.items():\n",
    "    alpha0_mean[alpha] = 0.5 * (lims[0] + lims[1])\n",
    "\n",
    "ensemble = Annular(**alpha0_mean)\n",
    "\n",
    "filter_params = dict(m= 20, \n",
    "                     std_psi=0.3,\n",
    "                     std_a=alpha0)\n",
    "\n",
    "# Forecast model to initialise the ensemble after transient\n",
    "state, t_ = ensemble.time_integrate(int(ensemble.t_CR / ensemble.dt))\n",
    "ensemble.update_history(state[-1], reset=True)\n",
    "\n",
    "ensemble.init_ensemble(**filter_params)\n",
    "ensemble.close()\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ffcdafa5e0a447e"
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.create import create_ensemble\n",
    "alpha0 = dict(nu=(-15., 30.),\n",
    "              c2beta=(10, 50),\n",
    "              kappa=(1.E-4, 2.E-4),\n",
    "              epsilon=(5e-3, 8e-3),\n",
    "              omega=(1090 * 2 * np.pi, 1095 * 2 * np.pi),\n",
    "              theta_b=(0.5, 0.7),\n",
    "              theta_e=(0.4, 0.6)\n",
    "              )\n",
    "\n",
    "forecast_params = dict(model=Annular, \n",
    "                       dt=truth['dt'], \n",
    "                       m=50, \n",
    "                       std_psi=0.3, \n",
    "                       std_a=alpha0\n",
    "                       )\n",
    "\n",
    "ensemble = create_ensemble(**forecast_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:14.382022Z",
     "start_time": "2024-04-17T18:47:14.356490Z"
    }
   },
   "id": "846679d6cf1ed5e4",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(truth['dt'])\n",
    "print(ensemble.t_transient / 3.)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:14.475682Z",
     "start_time": "2024-04-17T18:47:14.383669Z"
    }
   },
   "id": "53e14a1aad285f70",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize ensemble initialization\n",
    "# from essentials.plotResults import plot_ensemble\n",
    "# plot_ensemble(ensemble, reference_params={'kappa': 1e-4, 'omega': 2 * np.pi, 'epsilon': 1e-3})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:14.591212Z",
     "start_time": "2024-04-17T18:47:14.478329Z"
    }
   },
   "id": "c826276b3939c82c",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Train an ESN to model the model bias\n",
    "The procedure is the following\n",
    "\n",
    "&emsp; i. Initialise ESN Bias class object\n",
    "&emsp; ii. Create synthetic bias to use as training data \n",
    "&emsp; iii. Train the ESN\n",
    "&emsp; iv. Create washout data\n",
    "\n",
    "<br><br>\n",
    "**4.1. Initialise the ESN**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9155103d82f09d8"
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.create import create_bias_training_dataset\n",
    "\n",
    "ensemble_ESN = ensemble.copy()\n",
    "\n",
    "train_params = dict(bias_model=ESN, \n",
    "                    upsample=5,\n",
    "                    N_units=50,\n",
    "                    N_wash=10,\n",
    "                    t_train=ensemble.t_transient / 3.,\n",
    "                    t_test=ensemble.t_CR * 2,\n",
    "                    t_val=ensemble.t_CR * 2,\n",
    "                    # Training data generation options\n",
    "                    augment_data=True,\n",
    "                    biased_observations=True,\n",
    "                    seed_W=0,\n",
    "                    N_folds=4,\n",
    "                    L=50,\n",
    "                    std_a=alpha0,\n",
    "                    # Hyperparameter search ranges\n",
    "                    rho_range=(0.5, 1.),\n",
    "                    sigma_in_range=(np.log10(1e-5), np.log10(1e1)),\n",
    "                    tikh_range=[1e-12, 1e-9]\n",
    "                    )\n",
    "\n",
    "ensemble_ESN.init_bias(**train_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:14.711161Z",
     "start_time": "2024-04-17T18:47:14.594Z"
    }
   },
   "id": "5c9a4acf4f81d58d",
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "|\n",
    "**4.2. Create training data**\n",
    "\n",
    "The details of the code inside ```create_bias_training_dataset()``` function is explained in the tutorial ```Class_Bias.ipynb```."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4337f57a7cebf3a"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# train_data = np.load('train_data', allow_pickle=True)\n",
    "train_data = create_bias_training_dataset(truth['y_raw'],\n",
    "                                          truth['y_true'], ensemble_ESN, **train_params)\n",
    "# \n",
    "# np.save('train_data', train_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:24.931451Z",
     "start_time": "2024-04-17T18:47:14.713856Z"
    }
   },
   "id": "cdf8ed52ecae7fa9",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualize training data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7e07941abd8d071"
  },
  {
   "cell_type": "code",
   "source": [
    "#TODO\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:47:24.940232Z",
     "start_time": "2024-04-17T18:47:24.935043Z"
    }
   },
   "id": "b0f34ff303401986",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**4.3. Train the ESN**\n",
    "\n",
    "The training convergence, hyperparameter optimization and testing results are saved in a pdf file in *figs_ESN* folder."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e96d2997ea3b2075"
  },
  {
   "cell_type": "code",
   "source": [
    "ensemble_ESN.bias.train_bias_model(**train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:52:29.918608Z",
     "start_time": "2024-04-17T18:47:24.943005Z"
    }
   },
   "id": "ddb04bc57eacba42",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4.4. Create washout data**\n",
    "\n",
    "We retrieve from the raw data a ```N_wash``` number of observations to use for initialising the ESN, i.e., to perform the washout. \n",
    "The ESN initialization must be before the fist observation.\n",
    "\n",
    "```\n",
    "from essentials.create import create_washout\n",
    "wash_t, wash_obs = create_washout(ensemble.bias, t=t_true, y_raw=y_raw)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ba47fc4b7bffcb"
  },
  {
   "cell_type": "code",
   "source": [
    "ensemble_ESN.bias.t_init = truth['t_obs'][0] - 2 * truth['dt_obs']\n",
    "\n",
    "i1 = np.argmin(abs(ensemble_ESN.bias.t_init - truth['t']))\n",
    "i0 = i1 - ensemble_ESN.bias.N_wash  * ensemble_ESN.bias.upsample \n",
    "\n",
    "wash_obs = truth['y_raw'][i0:i1 + 1:ensemble_ESN.bias.upsample]\n",
    "wash_t = truth['t'][i0:i1 + 1:ensemble_ESN.bias.upsample]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:52:29.942393Z",
     "start_time": "2024-04-17T18:52:29.920817Z"
    }
   },
   "id": "187c7776666ba83",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Apply data assimilation\n",
    "We now have all the ingredients to start our data assimilation algorithm."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0007caf0a985fcb"
  },
  {
   "cell_type": "code",
   "source": [
    "t_start = Annular.t_transient\n",
    "t_stop = t_start + Annular.t_CR * 35\n",
    "\n",
    "\n",
    "truth_og = create_truth(model = data_folder + 'annular/ER_{}'.format(ER),\n",
    "                     t_start = t_start,\n",
    "                     t_stop = t_stop,\n",
    "                     Nt_obs = 30,\n",
    "                     t_max = t_stop + Annular.t_transient,\n",
    "                     post_processed=False\n",
    "                     )\n",
    "\n",
    "truth['wash_obs'] = wash_obs\n",
    "truth['wash_t'] = wash_t\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:52:32.931886Z",
     "start_time": "2024-04-17T18:52:29.944467Z"
    }
   },
   "id": "2eb57d197d830c3f",
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rng = np.random.default_rng(6)\n",
    "\n",
    "forecast_params['m'] = 20\n",
    "forecast_params['std_a'] = dict(nu=(-10., 20.),\n",
    "                                c2beta=(10, 50),\n",
    "                                kappa=(1.E-4, 2.E-4),\n",
    "                                epsilon=(5e-3, 8e-3),\n",
    "                                omega=(1090 * 2 * np.pi, 1095 * 2 * np.pi),\n",
    "                                theta_b=(0.5, 0.7),\n",
    "                                theta_e=(0.4, 0.6)\n",
    "                                )\n",
    "\n",
    "filter_ensemble = create_ensemble(**forecast_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:52:32.981843Z",
     "start_time": "2024-04-17T18:52:32.935096Z"
    }
   },
   "id": "61bc414c3c69d498",
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.DA import *\n",
    "from essentials.Util import save_to_pickle_file\n",
    "\n",
    "truth = truth_og.copy()\n",
    "# save_to_pickle_file(results_dir + '', truth, out, bias, ensemble)\n",
    "\n",
    "out = []\n",
    " # --------------\n",
    "name = 'simulation_output_all'\n",
    "\n",
    "\n",
    "ens_bb = filter_ensemble.copy()\n",
    "ens_bb.t_init = truth['t_obs'][0]\n",
    "ens_bb.inflation = 1.0\n",
    "ens_bb.reject_inflation = 1.0\n",
    "\n",
    "ens_ba = ens_bb.copy()\n",
    "ens_ba.bias = ensemble_ESN.bias.copy()\n",
    "\n",
    "\n",
    "DA_kwargs = dict(y_obs=truth['y_obs'].copy(), t_obs=truth['t_obs'].copy(), std_obs=0.1, wash_obs=wash_obs.copy(), wash_t=wash_t.copy())\n",
    "\n",
    "for kf in ['rBA_EnKF', 'EnKF']:\n",
    "    \n",
    "    if kf[0] == 'r':\n",
    "        ks = np.linspace(0, 5, 6)\n",
    "        blank_ens = ens_ba.copy()\n",
    "    else:\n",
    "        ks = [None]\n",
    "        blank_ens = ens_bb.copy()\n",
    "\n",
    "    blank_ens.filter = kf\n",
    "    for kk in ks:\n",
    "        ens = blank_ens.copy()\n",
    "        \n",
    "        if kf[0] == 'r':\n",
    "            ens.regularization_factor = kk\n",
    "\n",
    "        \n",
    "        filter_ens = dataAssimilation(ens, **DA_kwargs.copy())\n",
    "        \n",
    "        #Forecast the ensemble further without assimilation\n",
    "        Nt_extra = int(filter_ens.t_CR / filter_ens.dt) * 10\n",
    "        \n",
    "        psi, t = filter_ens.time_integrate(Nt_extra)\n",
    "        filter_ens.update_history(psi, t)\n",
    "        \n",
    "        y = filter_ens.get_observable_hist(Nt_extra)\n",
    "        b, t_b = filter_ens.bias.time_integrate(t=t, y=y)\n",
    "        filter_ens.bias.update_history(b, t_b)\n",
    "        \n",
    "        filter_ens.close()\n",
    "        \n",
    "        out.append(filter_ens.copy())\n",
    "\n",
    "results_dir = 'results/ER{}/m{}/'.format(ER, out[0].m)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "save_to_pickle_file(results_dir + name, truth, out, ensemble_ESN.bias, ensemble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:56:04.145443Z",
     "start_time": "2024-04-17T18:52:32.984712Z"
    }
   },
   "id": "bc1a30086c60e94c",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.plotResults import print_parameter_results\n",
    "from essentials.plotResults import plot_states_PDF, plot_RMS_pdf\n",
    "\n",
    "truth_params = dict()\n",
    "for param in Annular.params:\n",
    "    if param == 'nu':\n",
    "        truth_params[param] = Annular.nu_from_ER(ER)\n",
    "    elif param == 'c2beta':\n",
    "        truth_params[param] = Annular.c2beta_from_ER(ER)\n",
    "    else:\n",
    "        truth_params[param] = Annular.defaults[param]\n",
    "\n",
    "print_parameter_results(out, true_values=truth_params)\n",
    "               \n",
    "truth['wash_t'] = wash_t\n",
    "truth['wash_obs'] = wash_obs\n",
    "\n",
    "windows = [(truth['t_obs'][-1], truth['t_obs'][-1] + out[0].t_CR * 1),\n",
    "           (truth['t_obs'][-1], truth['t_obs'][-1] + out[0].t_CR * 5)]\n",
    "\n",
    "for window, sub in zip(windows, ['short']):\n",
    "    plot_states_PDF(out, truth, nbins=20, window=window)\n",
    "    plt.savefig(results_dir + 'plot_states_PDF_' + sub + '.pdf')\n",
    "\n",
    "\n",
    "plot_RMS_pdf(out, truth, nbins=20)\n",
    "plt.savefig(results_dir + 'plot_RMS_pdf' + '.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:56:56.329239Z",
     "start_time": "2024-04-17T18:56:04.148968Z"
    }
   },
   "id": "18fb41f65a0e327b",
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from essentials.plotResults import plot_timeseries, plot_parameters, plot_covarriance#\n",
    "\n",
    "for filter_ens in out:\n",
    "    plot_timeseries(filter_ens, truth_og)\n",
    "    plot_parameters(filter_ens, truth_og)\n",
    "    plot_covarriance(filter_ens)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T18:57:32.238346Z",
     "start_time": "2024-04-17T18:56:56.330589Z"
    }
   },
   "id": "2ecd64970052a1eb",
   "execution_count": 42,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
